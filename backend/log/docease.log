[ 2024-11-19 14:55:31,631 ]  Module: log.py | Function: <module> | Line No: 19 -  INFO: Logging started!
[ 2024-11-19 14:55:32,116 ]  Module: connectionpool.py | Function: _new_conn | Line No: 1051 -  DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[ 2024-11-19 14:55:32,437 ]  Module: connectionpool.py | Function: _make_request | Line No: 546 -  DEBUG: https://huggingface.co:443 "GET /api/models/qdrant/bge-base-en-v1.5-onnx-q/revision/main HTTP/11" 307 91
[ 2024-11-19 14:55:32,889 ]  Module: connectionpool.py | Function: _make_request | Line No: 546 -  DEBUG: https://huggingface.co:443 "GET /api/models/Qdrant/bge-base-en-v1.5-onnx-Q/revision/main HTTP/11" 200 1560
[ 2024-11-19 14:55:33,274 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:55:33,274 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:55:33,585 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:55:33,586 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:55:33,910 ]  Module: _internal.py | Function: _log | Line No: 97 -  INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
[ 2024-11-19 14:55:33,910 ]  Module: _internal.py | Function: _log | Line No: 97 -  INFO: [33mPress CTRL+C to quit[0m
[ 2024-11-19 14:55:53,804 ]  Module: proactor_events.py | Function: __init__ | Line No: 633 -  DEBUG: Using proactor: IocpProactor
[ 2024-11-19 14:55:53,915 ]  Module: local.py | Function: __init__ | Line No: 351 -  DEBUG: open file: D:/personal/Personal Projects/DocEase~Chat with Pdf/backend/Data/Pdf_Store/92aa923c-e321-4ee8-a565-08b91f7c0588.pdf
[ 2024-11-19 14:55:53,958 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:55:53,960 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:55:55,056 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:55:55,403 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B73912F90>
[ 2024-11-19 14:55:55,403 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BD7F0> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:55:55,629 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B738F17D0>
[ 2024-11-19 14:55:55,630 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'POST']>
[ 2024-11-19 14:55:55,632 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:55:55,632 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'POST']>
[ 2024-11-19 14:55:55,856 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:55:55,856 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'POST']>
[ 2024-11-19 14:55:56,706 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:25:56 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a568c83e-01ac-434d-85fe-9f47203b602f'), (b'x-correlation-id', b'e1a8dc93-7400-4769-98cc-7a2adb9c6c6d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:55:56,708 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[ 2024-11-19 14:55:56,708 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'POST']>
[ 2024-11-19 14:55:56,709 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:55:56,709 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:55:56,709 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:55:56,710 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:55:56,711 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:55:57,715 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:55:57,717 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:55:58,803 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:55:59,033 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B739447D0>
[ 2024-11-19 14:55:59,034 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BD880> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:55:59,244 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B738EBE90>
[ 2024-11-19 14:55:59,244 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:55:59,245 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:55:59,246 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:55:59,246 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:55:59,246 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:55:59,485 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:25:58 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'f1f35ec1-9e49-4347-bf49-5ad257cc846a'), (b'x-correlation-id', b'3cf9c9ee-1d89-4890-b289-2fdb9a0e4917'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:55:59,486 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e0e1950-4ea6-469e-9d2f-7cfae3932168 "HTTP/1.1 200 OK"
[ 2024-11-19 14:55:59,486 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:55:59,487 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:55:59,487 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:55:59,487 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:00,498 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:56:00,498 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:56:01,510 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:56:01,512 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:56:02,580 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:56:02,861 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B738EBED0>
[ 2024-11-19 14:56:02,862 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BE2A0> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:56:03,082 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B7392AC10>
[ 2024-11-19 14:56:03,083 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:03,084 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:03,084 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:03,084 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:03,084 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:03,328 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:02 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'5cb57d22-6db0-483e-adb0-c3fef84ae2a8'), (b'x-correlation-id', b'4c947ea0-bf89-4077-b3c9-ac7a8edc26ba'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:03,328 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e0e1950-4ea6-469e-9d2f-7cfae3932168 "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:03,329 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:03,329 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:03,330 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:03,330 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:04,341 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:56:04,342 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:56:05,349 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:56:05,352 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:56:05,691 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:56:05,923 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B73944C90>
[ 2024-11-19 14:56:05,924 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BF1D0> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:56:06,136 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B735BE2D0>
[ 2024-11-19 14:56:06,137 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:06,138 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:06,139 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:06,139 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:06,139 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:06,371 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c63899d0-6550-432d-9f03-2d182588773e'), (b'x-correlation-id', b'fb68e307-9c56-4863-ad6b-43f08c4cf123'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:06,371 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e0e1950-4ea6-469e-9d2f-7cfae3932168 "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:06,372 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:06,372 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:06,372 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:06,372 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:07,376 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:56:07,383 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:56:08,391 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:56:08,393 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:56:08,747 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:56:08,978 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B7394C290>
[ 2024-11-19 14:56:08,978 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BF260> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:56:09,192 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B738F02D0>
[ 2024-11-19 14:56:09,193 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:09,194 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:09,194 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:09,194 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:09,194 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:09,424 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'cc014b62-0a8e-4e35-b1df-a332e9881a8d'), (b'x-correlation-id', b'b3490cbb-d38a-445a-878f-44ca6dc687a0'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:09,425 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e0e1950-4ea6-469e-9d2f-7cfae3932168 "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:09,425 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:09,425 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:09,426 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:09,426 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:10,437 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:56:10,437 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:56:11,449 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:56:11,451 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:56:11,766 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:56:11,988 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B7394DF50>
[ 2024-11-19 14:56:11,989 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BF2F0> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:56:12,317 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B738B0B90>
[ 2024-11-19 14:56:12,317 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:12,318 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:12,318 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:12,318 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:12,318 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:12,602 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:11 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'69dfd5f5-9bd1-4309-a26e-38c91f265bec'), (b'x-correlation-id', b'7e621108-faeb-4497-bf10-275f8eebcb2e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:12,603 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e0e1950-4ea6-469e-9d2f-7cfae3932168 "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:12,603 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:12,603 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:12,603 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:12,604 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:13,605 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:56:13,611 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:56:14,627 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:56:14,628 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:56:14,932 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:56:15,167 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B7394FED0>
[ 2024-11-19 14:56:15,167 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BD7F0> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:56:15,511 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B7394FFD0>
[ 2024-11-19 14:56:15,512 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:15,513 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:15,513 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:15,513 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:15,513 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:15,738 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a1125ac1-5361-498d-9e77-d289b4cf915f'), (b'x-correlation-id', b'8ec104e1-4b5d-4597-80ef-7bb28142eee7'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:15,739 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e0e1950-4ea6-469e-9d2f-7cfae3932168 "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:15,739 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:15,740 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:15,740 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:15,740 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:15,741 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:15,742 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:15,742 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:15,742 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:15,742 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:16,201 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'13344'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c76957df-868e-4364-aae7-73b3d7242f5d'), (b'x-correlation-id', b'10a1aba7-bab4-4ed6-a74f-7d2856e9473a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:16,202 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e0e1950-4ea6-469e-9d2f-7cfae3932168/result/markdown "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:16,202 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:16,203 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:16,204 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:16,204 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:16,204 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:56:16,205 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:56:24,243 ]  Module: local.py | Function: __init__ | Line No: 351 -  DEBUG: open file: D:/personal/Personal Projects/DocEase~Chat with Pdf/backend/Data/Pdf_Store/92aa923c-e321-4ee8-a565-08b91f7c0588.pdf
[ 2024-11-19 14:56:24,244 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:56:24,246 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:56:24,621 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:56:24,847 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B735D3910>
[ 2024-11-19 14:56:24,848 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BE060> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:56:25,053 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B738A3D50>
[ 2024-11-19 14:56:25,053 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'POST']>
[ 2024-11-19 14:56:25,054 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:25,054 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'POST']>
[ 2024-11-19 14:56:25,260 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:25,260 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'POST']>
[ 2024-11-19 14:56:26,141 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:25 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'9279145e-e101-4b59-ad57-f5b0c83d6274'), (b'x-correlation-id', b'3b299f35-72bb-4606-850b-492539a8d806'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:26,142 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:26,142 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'POST']>
[ 2024-11-19 14:56:26,143 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:26,143 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:26,143 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:26,144 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:56:26,144 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:56:27,151 ]  Module: _config.py | Function: load_ssl_context | Line No: 82 -  DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
[ 2024-11-19 14:56:27,153 ]  Module: _config.py | Function: load_ssl_context_verify | Line No: 148 -  DEBUG: load_verify_locations cafile='C:\\Users\\shubham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\certifi\\cacert.pem'
[ 2024-11-19 14:56:27,461 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=5000 socket_options=None
[ 2024-11-19 14:56:27,695 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B73946610>
[ 2024-11-19 14:56:27,696 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BF530> server_hostname='api.cloud.llamaindex.ai' timeout=5000
[ 2024-11-19 14:56:27,912 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000024B735CD650>
[ 2024-11-19 14:56:27,913 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:27,913 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:27,913 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:27,914 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:27,914 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:28,159 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:27 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'995deb64-3c6a-42d0-bb78-cc042a8e727c'), (b'x-correlation-id', b'623ba8a2-a9a0-401a-9354-99e78218311c'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:28,159 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7671ff45-cf2a-4627-8e34-9c1e7fac377a "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:28,160 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:28,160 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:28,160 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:28,160 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:28,161 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:28,163 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:28,163 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:28,163 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:28,163 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.started request=<Request [b'GET']>
[ 2024-11-19 14:56:28,588 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:27 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'13343'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c298ce55-216a-454e-9f04-b44429823142'), (b'x-correlation-id', b'6307b304-5664-4e31-83fb-9366390dcd8f'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[ 2024-11-19 14:56:28,588 ]  Module: _client.py | Function: _send_single_request | Line No: 1786 -  INFO: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7671ff45-cf2a-4627-8e34-9c1e7fac377a/result/markdown "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:28,589 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.started request=<Request [b'GET']>
[ 2024-11-19 14:56:28,589 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:28,589 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:28,590 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:28,590 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.started
[ 2024-11-19 14:56:28,591 ]  Module: _trace.py | Function: atrace | Line No: 85 -  DEBUG: close.complete
[ 2024-11-19 14:56:28,751 ]  Module: connectionpool.py | Function: _new_conn | Line No: 1051 -  DEBUG: Starting new HTTPS connection (1): packages.unstructured.io:443
[ 2024-11-19 14:56:29,183 ]  Module: connectionpool.py | Function: _make_request | Line No: 546 -  DEBUG: https://packages.unstructured.io:443 "GET /python-telemetry?version=0.15.13&platform=Windows&python3.11&arch=AMD64&gpu=False&dev=false HTTP/11" 302 None
[ 2024-11-19 14:56:29,185 ]  Module: connectionpool.py | Function: _new_conn | Line No: 1051 -  DEBUG: Starting new HTTPS connection (1): unstructured.io:443
[ 2024-11-19 14:56:29,225 ]  Module: connectionpool.py | Function: _make_request | Line No: 546 -  DEBUG: https://unstructured.io:443 "GET /?version=0.15.13&platform=Windows&python3.11&arch=AMD64&gpu=False&dev=false HTTP/11" 200 15199
[ 2024-11-19 14:56:29,813 ]  Module: core.py | Function: registerExtensions | Line No: 182 -  DEBUG: Successfully loaded extension "markdown.extensions.tables.TableExtension".
[ 2024-11-19 14:56:29,878 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Not narrative. Text exceeds cap ratio 0.5:

CHIRAG SUBRAMANIAN (224) 622-1395 | chirag1810@gmail.com
[ 2024-11-19 14:56:29,901 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Sentence does not exceed 3 word tokens, it will not count toward sentence count.
US
[ 2024-11-19 14:56:29,902 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Sentence does not exceed 3 word tokens, it will not count toward sentence count.
US
[ 2024-11-19 14:56:29,903 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Not narrative. Text exceeds cap ratio 0.5:

CHIRAG SUBRAMANIAN (224) 622-1395 | chirag1810@gmail.com
[ 2024-11-19 14:56:29,906 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Not narrative. Text exceeds cap ratio 0.5:

Professional Experience, Continued…
[ 2024-11-19 14:56:29,906 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Sentence does not exceed 5 word tokens, it will not count toward sentence count.
Professional Experience Continued
[ 2024-11-19 14:56:29,916 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Not narrative. Text exceeds cap ratio 0.5:

EDUCATION, CERTIFICATIONS & PROFESSIONAL DEVELOPMENT
[ 2024-11-19 14:56:29,917 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Sentence does not exceed 5 word tokens, it will not count toward sentence count.
EDUCATION CERTIFICATIONS  PROFESSIONAL DEVELOPMENT
[ 2024-11-19 14:56:29,920 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Not narrative. Text exceeds cap ratio 0.5:

GEORGIA INSTITUTE OF TECHNOLOGY, ATLANTA, GA, USA Master of Science in Analytics – Specialization in Computational Data Analytics (Expected 12/2024) Relevant Courses: Deep Learning, Reinforcement Learning, Machine Learning, Regression Analysis, Database System Concepts and Design, Computing for Data Analysis, Introduction to Analytics Modeling, Data and Visual Analytics, Deterministic Operations Research, Business Fundamentals for Analytics, Data Analytics in Business, Applied Analytics Practicum
[ 2024-11-19 14:56:29,926 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Not narrative. Text exceeds cap ratio 0.5:

NORTHEASTERN UNIVERSITY, BOSTON, MA, USA Master of Science in Operations Research (Graduated 08/2016) Relevant Courses: Deterministic Operations Research, Applied Probability and Statistics, Probabilistic Operations Research, Data Mining in Engineering, Statistical Data Mining, Optimization and Complexity, Master’s Thesis
[ 2024-11-19 14:56:29,931 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Not narrative. Text exceeds cap ratio 0.5:

STANFORD UNIVERSITY, STANFORD, CA, USA Summer School: Statistics Courses (Earned Credit 08/2015)
[ 2024-11-19 14:56:29,934 ]  Module: logger.py | Function: detail | Line No: 16 -  DETAIL: Not narrative. Text exceeds cap ratio 0.5:

MANIPAL INSTITUTE OF TECHNOLOGY, MANIPAL, INDIA Bachelor of Engineering in Mechanical Engineering (Graduated 05/2014)
[ 2024-11-19 14:56:31,469 ]  Module: posthog.py | Function: __init__ | Line No: 20 -  INFO: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
[ 2024-11-19 14:56:31,647 ]  Module: config.py | Function: start | Line No: 306 -  DEBUG: Starting component System
[ 2024-11-19 14:56:31,647 ]  Module: config.py | Function: start | Line No: 306 -  DEBUG: Starting component Posthog
[ 2024-11-19 14:56:31,647 ]  Module: config.py | Function: start | Line No: 306 -  DEBUG: Starting component OpenTelemetryClient
[ 2024-11-19 14:56:31,647 ]  Module: config.py | Function: start | Line No: 306 -  DEBUG: Starting component SqliteDB
[ 2024-11-19 14:56:31,849 ]  Module: config.py | Function: start | Line No: 306 -  DEBUG: Starting component QuotaEnforcer
[ 2024-11-19 14:56:31,849 ]  Module: config.py | Function: start | Line No: 306 -  DEBUG: Starting component LocalSegmentManager
[ 2024-11-19 14:56:31,850 ]  Module: config.py | Function: start | Line No: 306 -  DEBUG: Starting component SegmentAPI
[ 2024-11-19 14:56:32,379 ]  Module: connectionpool.py | Function: _new_conn | Line No: 1051 -  DEBUG: Starting new HTTPS connection (1): us.i.posthog.com:443
[ 2024-11-19 14:56:33,578 ]  Module: connectionpool.py | Function: _make_request | Line No: 546 -  DEBUG: https://us.i.posthog.com:443 "POST /batch/ HTTP/11" 200 15
[ 2024-11-19 14:56:35,954 ]  Module: config.py | Function: start | Line No: 306 -  DEBUG: Starting component PersistentLocalHnswSegment
[ 2024-11-19 14:56:36,029 ]  Module: _internal.py | Function: _log | Line No: 97 -  INFO: 127.0.0.1 - - [19/Nov/2024 14:56:36] "POST /upload HTTP/1.1" 200 -
[ 2024-11-19 14:56:43,149 ]  Module: _internal.py | Function: _log | Line No: 97 -  INFO: 127.0.0.1 - - [19/Nov/2024 14:56:43] "OPTIONS /chat HTTP/1.1" 200 -
[ 2024-11-19 14:56:43,171 ]  Module: segment.py | Function: create_collection | Line No: 187 -  DEBUG: Collection rag already exists, returning existing collection.
[ 2024-11-19 14:56:43,232 ]  Module: _base_client.py | Function: _build_request | Line No: 445 -  DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are an AI language model assistant. Your task is \n    to generate 3 different versions of the given user \n    question to retrieve relevant documents from a vector  database. \n    By generating multiple perspectives on the user question, \n    your goal is to help the user overcome some of the limitations \n    of distance-based similarity search. Provide these alternative \n    questions separated by newlines. Original question: provide me summary '}], 'model': 'mixtral-8x7b-32768', 'n': 1, 'stream': False, 'temperature': 1e-08}}
[ 2024-11-19 14:56:43,251 ]  Module: _base_client.py | Function: _request | Line No: 948 -  DEBUG: Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
[ 2024-11-19 14:56:43,252 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
[ 2024-11-19 14:56:43,651 ]  Module: connectionpool.py | Function: _make_request | Line No: 546 -  DEBUG: https://us.i.posthog.com:443 "POST /batch/ HTTP/11" 200 15
[ 2024-11-19 14:56:43,664 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024B7395AE90>
[ 2024-11-19 14:56:43,665 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024B737BD910> server_hostname='api.groq.com' timeout=None
[ 2024-11-19 14:56:43,690 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024B738C7090>
[ 2024-11-19 14:56:43,690 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: send_request_headers.started request=<Request [b'POST']>
[ 2024-11-19 14:56:43,691 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:43,691 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: send_request_body.started request=<Request [b'POST']>
[ 2024-11-19 14:56:43,692 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:43,692 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: receive_response_headers.started request=<Request [b'POST']>
[ 2024-11-19 14:56:44,771 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'5000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'4895'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.26s'), (b'x-request-id', b'req_01jd1vxrymfxnrrawcrgw78vqx'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=KBXfyeV8orbdYV7.kZH.CDvWWL9AcGCkmU7GTIKIYvM-1732008404-1.0.1.1-ejdO8bxEr384O9YDe5Iso9ll0ehsd1vs7opzvQWvv2K50pBJ.1fXQU__Z8Celk02BA9pmvxoNZIc2s2QIduGzw; path=/; expires=Tue, 19-Nov-24 09:56:44 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e4f2907cdcc47ea-BOM'), (b'Content-Encoding', b'gzip')])
[ 2024-11-19 14:56:44,773 ]  Module: _client.py | Function: _send_single_request | Line No: 1038 -  INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:44,773 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: receive_response_body.started request=<Request [b'POST']>
[ 2024-11-19 14:56:44,774 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:44,774 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:44,774 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:44,775 ]  Module: _base_client.py | Function: _request | Line No: 987 -  DEBUG: HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 19 Nov 2024 09:26:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '5000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '4895', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.26s', 'x-request-id': 'req_01jd1vxrymfxnrrawcrgw78vqx', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=KBXfyeV8orbdYV7.kZH.CDvWWL9AcGCkmU7GTIKIYvM-1732008404-1.0.1.1-ejdO8bxEr384O9YDe5Iso9ll0ehsd1vs7opzvQWvv2K50pBJ.1fXQU__Z8Celk02BA9pmvxoNZIc2s2QIduGzw; path=/; expires=Tue, 19-Nov-24 09:56:44 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8e4f2907cdcc47ea-BOM', 'content-encoding': 'gzip'})
[ 2024-11-19 14:56:44,815 ]  Module: multi_query.py | Function: generate_queries | Line No: 191 -  INFO: Generated queries: ['1. Could you give me a brief overview of the main points?', '2. Can you summarize the key details for me?', '3. Is it possible to present the essential information in a condensed format?']
[ 2024-11-19 14:56:45,078 ]  Module: local_persistent_hnsw.py | Function: query_vectors | Line No: 348 -  WARNING: Number of requested results 10 is greater than number of elements in index 8, updating n_results = 8
[ 2024-11-19 14:56:45,367 ]  Module: local_persistent_hnsw.py | Function: query_vectors | Line No: 348 -  WARNING: Number of requested results 10 is greater than number of elements in index 8, updating n_results = 8
[ 2024-11-19 14:56:45,487 ]  Module: connectionpool.py | Function: _make_request | Line No: 546 -  DEBUG: https://us.i.posthog.com:443 "POST /batch/ HTTP/11" 200 15
[ 2024-11-19 14:56:45,664 ]  Module: local_persistent_hnsw.py | Function: query_vectors | Line No: 348 -  WARNING: Number of requested results 10 is greater than number of elements in index 8, updating n_results = 8
[ 2024-11-19 14:56:45,726 ]  Module: segment.py | Function: create_collection | Line No: 187 -  DEBUG: Collection rag already exists, returning existing collection.
[ 2024-11-19 14:56:46,315 ]  Module: connectionpool.py | Function: _make_request | Line No: 546 -  DEBUG: https://us.i.posthog.com:443 "POST /batch/ HTTP/11" 200 15
[ 2024-11-19 14:56:48,150 ]  Module: _base_client.py | Function: _build_request | Line No: 445 -  DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "\n                You are a helpful chat assistant named DocEase, specializing in tasks related to PDF data. You will get PDF content, and your task is to answer questions based on that content.\n\n                Your key expertise includes:\n                0. Provide your Introduction and features at start on conversation in response to question such as 'Hi','Hello'.Give suggestion to user which questions they can ask based on our below mentioned features.\n                1. Answering questions based on the content of PDFs.\n                2. Translating PDF data between multiple languages, including English, Marathi, and Hindi (and vice versa).\n                3. Summarizing PDF content.\n                4. Providing answers in an engaging and clear format.\n\n\n                **Instructions:**\n                - If the exact answer is not available in the PDF, provide the best possible answer based on your understanding.\n                - Keep your responses concise, informative, and user-friendly.\n                - Format your answers using **Markdown** for clarity and readability, including headings, bullet points, and code blocks when necessary.\n                - Do Not start response with Answer keyword.\n\n                **Context:**  \n                Built and deployed a Credit Card Propensity Tool prediction framework (propensity model) for Walgreens Front of Store Customers in Python using an XGBOOST multi-class classification model. Wrote an efficient data processing PySpark pipeline and successfully scored 132M customers using the trained XGBOOST model. The propensity scores from the model are being used to generate new credit card offers for Walgreens customers.\n\nEngineered complex and efficient SQL queries processing >40B rows of data via Microsoft Azure Databricks, creating a robust Customer Demographics Table and Store Level Insights Dashboard in PowerBI.\n\nLed the development of Aon Impact Forecasting’s U.S. Severe Convective Storm Probabilistic Catastrophe model, spatially simulating their largest ever stochastic event set of 609M rows in R.\n\nPROFESSIONAL EXPERIENCE\n\nExtracted Text Content\n\nCHIRAG SUBRAMANIAN (224) 622-1395 | chirag1810@gmail.com\n\nProfessional experience, continued… - Reviewed SQL code written by junior associates and gave them best practices recommendations. - Mentored and guided junior associates. - Acted as the lead interviewer for Associate Data Scientist roles in the company.\n\nHOLLAND AMERICA LINE, Chicago, IL Oct 2021 – April 2022 Senior Marketing Analytics Analyst I was recruited to the organization to contribute towards predictive modeling, A/B testing, customer segmentation analytics, statistical modeling and reporting to drive marketing strategies for Holland America Line. - Applied the k-means() algorithm in R for optimal customer segmentation. - Data wrangling in R using dplyr, data.table, tidyverse, tidyr and lubridate packages. - Data wrangling in Python using numpy, pandas and scipy. - Writing complex SQL queries fetching data with >8M rows using TOAD for Oracle. - Creating interactive dashboards and reports using Tableau. - Automating Excel reports and processes using R. - Manipulating data using Pivot Tables in Microsoft Excel.\n\nAlgorithm Lead Intern Researched technologies for developing a machine learning algorithm for the corporate social responsibility industry. - Built the first machine learning algorithm for the corporate social responsibility (CSR) industry.\n\nEDUCATION, CERTIFICATIONS & PROFESSIONAL DEVELOPMENT\n\nGEORGIA INSTITUTE OF TECHNOLOGY, ATLANTA, GA, USA Master of Science in Analytics – Specialization in Computational Data Analytics (Expected 12/2024) Relevant Courses: Deep Learning, Reinforcement Learning, Machine Learning, Regression Analysis, Database System Concepts and Design, Computing for Data Analysis, Introduction to Analytics Modeling, Data and Visual Analytics, Deterministic Operations Research, Business Fundamentals for Analytics, Data Analytics in Business, Applied Analytics Practicum\n\nNORTHEASTERN UNIVERSITY, BOSTON, MA, USA Master of Science in Operations Research (Graduated 08/2016) Relevant Courses: Deterministic Operations Research, Applied Probability and Statistics, Probabilistic Operations Research, Data Mining in Engineering, Statistical Data Mining, Optimization and Complexity, Master’s Thesis\n\nSTANFORD UNIVERSITY, STANFORD, CA, USA Summer School: Statistics Courses (Earned Credit 08/2015)\n\nMANIPAL INSTITUTE OF TECHNOLOGY, MANIPAL, INDIA Bachelor of Engineering in Mechanical Engineering (Graduated 05/2014)\n\nDocument Structure\n\nHeader: Name and contact information\n\nProfessional Experience: Detailed descriptions of roles and responsibilities\n\nEducation, Certifications & Professional Development: Academic qualifications and relevant courses\n\nNotes\n\nThe text has been extracted while preserving the formatting and logical flow.\n\nNo tables, diagrams, or mathematical equations were present in the provided content.\n\nThe document is structured hierarchically, with clear sections for professional experience and education.\n\nPROFESSIONAL EXPERIENCE\n\nWALGREENS BOOTS ALLIANCE, Chicago, IL Senior Data Scientist May 2022 – January 2024 I was recruited to the organization to contribute towards statistical machine learning, propensity modeling, statistical modeling, data wrangling, and reporting to drive marketing strategies for Walgreens Boots Alliance. TECH STACK - Python, R, SQL, PowerBI, Hadoop, Microsoft Azure Databricks, PySpark - Built a Customer Behavioral Progression propensity model for Walgreens Front of Store in Python using XGBOOST for multi-class classification. The model was trained on a dataset of 1.6M records and achieved an average accuracy of 85% across 10 classes on the test set. Wrote an efficient data processing PySpark pipeline and successfully scored a dataset of 200M+ records (all customers) using the trained XGBOOST model. Used insights from the last decision tree in the XGBOOST ensemble to make recommendations to the business. - Built and deployed a Credit Card Propensity Tool prediction framework (propensity model) for Walgreens Front of Store Customers in Python using an XGBOOST multi-class classification model on a dataset of 200K customers with an accuracy of 76% across 4 classes. Wrote an efficient data processing PySpark pipeline and successfully scored 132M customers using the trained XGBOOST model. The propensity scores from the model are being used to generate new credit card offers for Walgreens customers. - Engineered complex and efficient multi-layered SQL queries processing >40B rows of data via Microsoft Azure Databricks, creating a robust Customer Demographics Table and visualized it in a Store Level Insights Dashboard using PowerBI. - Performed K-means clustering in PySpark to segment a dataset of customers into groups based on customer behavior metrics. - Wrote complex SQL queries to pull data for ad hoc requests from internal business partners.\n\nExtracted Text Content\n\nCHIRAG SUBRAMANIAN (224) 622-1395 | chirag1810@gmail.com\n\nU.S. Florida Commission Project - Developed predictive models in R on datasets with more than 17 million rows. Machine Learning algorithms developed in R – generalized additive models, generalized linear models, neural networks and regression spline. - Performed statistical goodness of fit t-tests on claims data after aggregating the data to zipcode resolution using summarize() and group_by(), to compare the difference in means of the modeled data with the observed claims data at a 5% significance level. - Developed more than 1000 graphs and bar charts for different construction types and compared different sets of data after data cleaning and data wrangling. The visualizations I developed in R were important in assessing the accuracy and quality of Impact Forecasting’s catastrophe model for the Florida Loss Commission.\n\nAnalyst - Analytics Sep 2016 – Sep 2020 Provide predictive modeling and machine learning expertise utilizing Multiple Linear Regression, Boosted Decision Tree, K-Nearest Neighbors, K-means, Feed Forward Neural Networks, and Multi-Layer Neural Networks in R. Utilize probabilistic modeling and statistical analysis using R and presented models to teammates. Taught management R programming.\n\nU.S. Severe Convective Storm Model (SCS) - Spatially simulated the largest dataset in the history of Impact Forecasting’s SCS model - 609 million severe convective storm events, and improved model accuracy by developing a revolutionary 5 km by 5 km grid in R. - Executed loss calculation for 10 US states in the tornado model portion and wrote code in R for data wrangling, spatial simulation, data visualization, probabilistic modeling, looping and error handling. - Executed a gap statistic analysis using the K-Means algorithm in R to select the optimal number of tornado clusters.\n\nDocument Structure\n\nHeader: Name and contact information\n\nProfessional Experience: Detailed descriptions of roles and responsibilities at various companies, including:  \n\n                **Question:**  \n                {'provide me summary '}  \n\n                **Answer:**  \n                Please format your answer using Markdown as follows:\n                - **Headings** for important sections.\n                - **Bullet points** for lists or steps.\n                - **Code blocks** or **bold** for important terms or keywords.\n                - **Short paragraphs** for better readability.\n\n                For example:\n                - If you're explaining a concept, break it down into clear steps or bullet points.\n                - Use **bold** for key terms and phrases.\n                - Use headings like `### Summary`, `### Key Points`, `### Conclusion` to structure your response.\n\n                "}], 'model': 'mixtral-8x7b-32768', 'n': 1, 'stream': False, 'temperature': 1e-08}}
[ 2024-11-19 14:56:48,153 ]  Module: _base_client.py | Function: _request | Line No: 948 -  DEBUG: Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
[ 2024-11-19 14:56:48,154 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: send_request_headers.started request=<Request [b'POST']>
[ 2024-11-19 14:56:48,155 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: send_request_headers.complete
[ 2024-11-19 14:56:48,155 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: send_request_body.started request=<Request [b'POST']>
[ 2024-11-19 14:56:48,155 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: send_request_body.complete
[ 2024-11-19 14:56:48,156 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: receive_response_headers.started request=<Request [b'POST']>
[ 2024-11-19 14:56:49,588 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Nov 2024 09:26:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'5000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'2649'), (b'x-ratelimit-reset-requests', b'8.135999999s'), (b'x-ratelimit-reset-tokens', b'28.212s'), (b'x-request-id', b'req_01jd1vxwpveycbgbxfcpceamww'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e4f2923cf4447ea-BOM'), (b'Content-Encoding', b'gzip')])
[ 2024-11-19 14:56:49,590 ]  Module: _client.py | Function: _send_single_request | Line No: 1038 -  INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[ 2024-11-19 14:56:49,590 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: receive_response_body.started request=<Request [b'POST']>
[ 2024-11-19 14:56:49,591 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: receive_response_body.complete
[ 2024-11-19 14:56:49,591 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: response_closed.started
[ 2024-11-19 14:56:49,592 ]  Module: _trace.py | Function: trace | Line No: 45 -  DEBUG: response_closed.complete
[ 2024-11-19 14:56:49,592 ]  Module: _base_client.py | Function: _request | Line No: 987 -  DEBUG: HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 19 Nov 2024 09:26:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '5000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '2649', 'x-ratelimit-reset-requests': '8.135999999s', 'x-ratelimit-reset-tokens': '28.212s', 'x-request-id': 'req_01jd1vxwpveycbgbxfcpceamww', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8e4f2923cf4447ea-BOM', 'content-encoding': 'gzip'})
[ 2024-11-19 14:56:49,598 ]  Module: _internal.py | Function: _log | Line No: 97 -  INFO: 127.0.0.1 - - [19/Nov/2024 14:56:49] "POST /chat HTTP/1.1" 200 -
